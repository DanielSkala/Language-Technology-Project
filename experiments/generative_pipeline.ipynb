{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "ALready in current dir\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from typing import List, Tuple, Dict, Union, Any, Optional\n",
    "from tqdm import tqdm\n",
    "try:\n",
    "    os.chdir(os.path.join(os.getcwd(), '../../Language-Technology-Project'))\n",
    "    print(os.getcwd())\n",
    "except:\n",
    "    print(\"ALready in current dir\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size_gb(model) = 5.80 GB\n",
      "vocab size: 50257\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2-xl')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2-xl').to(device)\n",
    "\n",
    "print(f\"size_gb(model) = {model.num_parameters() * 4 / 1024**3:.2f} GB\")\n",
    "print(\"vocab size:\", tokenizer.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 9, 50257])\n",
      "Top 5 tokens:\n",
      "1:  woman (0.11)\n",
      "2:  doctor (0.08)\n",
      "3:  nurse (0.05)\n",
      "4:  mother (0.04)\n",
      "5:  man (0.03)\n"
     ]
    }
   ],
   "source": [
    "text = \"Man is a doctor as a women is a\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt').to(device)\n",
    "output = model(**encoded_input)\n",
    "print(output.logits.shape)\n",
    "next_token_logits = output.logits[:, -1, :]\n",
    "likelihoods = torch.softmax(next_token_logits, dim=-1)\n",
    "sorted_likelihoods, sorted_indices = torch.sort(likelihoods, descending=True)\n",
    "print(\"Top 5 tokens:\")\n",
    "for i in range(5):\n",
    "    print(f\"{i+1}: {tokenizer.decode(sorted_indices[0, i])} ({sorted_likelihoods[0, i]:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('4', 0.20943237841129303),\n",
       " ('5', 0.17149624228477478),\n",
       " ('6', 0.06978660076856613),\n",
       " ('7', 0.05673491582274437),\n",
       " ('8', 0.031708039343357086),\n",
       " ('9', 0.022482799366116524)]"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def get_likelihoods_of_words_given_context(prompt: str, words: list, model, tokenizer):\n",
    "    \"\"\"\n",
    "    Returns a list of likelihoods of words given a prompt.\n",
    "    \"\"\"\n",
    "    encoded_input = tokenizer(prompt, return_tensors='pt').to(device)\n",
    "    output = model(**encoded_input)\n",
    "    next_token_logits = output.logits[:, -1, :]\n",
    "    likelihoods = torch.softmax(next_token_logits, dim=-1)\n",
    "    word_probs = []\n",
    "    for word in words:\n",
    "        tokens = tokenizer.encode(word)\n",
    "        # word_probs.append(likelihoods[0, tokenizer.encode(word)[0]].item())\n",
    "        probability = 1\n",
    "        for token in tokens:\n",
    "            probability *= likelihoods[0, token].item()\n",
    "        word_probs.append(probability)\n",
    "    \n",
    "    output = list(zip(words, word_probs))\n",
    "    output.sort(key=lambda x: x[1], reverse=True)\n",
    "    return output\n",
    "# example\n",
    "prompt = \"2+2=\"\n",
    "options = [\"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]\n",
    "get_likelihoods_of_words_given_context(prompt, options, model, tokenizer)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Category classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "from settings import categories\n",
    "\n",
    "class LikelihoodBasedCategoryClassifier:\n",
    "\n",
    "    def __init__(self, categories):\n",
    "        self.categories = categories\n",
    "\n",
    "    def __shuffle_categories(self):\n",
    "        np.random.shuffle(self.categories)\n",
    "    \n",
    "    def __construct_classification_prompt(self, sentence, max_length=128, categories=None):\n",
    "        prompt = \"argument categories of Human Value Detection 2023 by name and description: \\n\\n\"\n",
    "        expectation2category = {}\n",
    "        for i, category in enumerate(categories):\n",
    "            name = category[\"name\"]\n",
    "            description = category[\"description\"]\n",
    "            examples = category[\"examples\"]\n",
    "            example = examples[np.random.randint(len(examples))]\n",
    "            example = example[:max_length] + \"...\" if len(example) > max_length else example\n",
    "            # otpions a-z\n",
    "            prompt += f\"{name}: {description} (e.g., {example})\\n\"\n",
    "            expectation2category[name] = name\n",
    "\n",
    "        prompt += \"\\n\\n\"\n",
    "        prompt += \"Classify the following sentence into one of the categories above:\\n\"\n",
    "        prompt += f\"\\n'Argument: {sentence}\"\n",
    "        prompt += \"\\Category: \"\n",
    "        return prompt, expectation2category\n",
    "\n",
    "    def classify_once(self, sentence: str) -> List[float]:\n",
    "        self.__shuffle_categories()\n",
    "        prompt, expectations = self.__construct_classification_prompt(sentence, categories=self.categories)\n",
    "        likelihoods = get_likelihoods_of_words_given_context(prompt, expectations.keys(), model, tokenizer)\n",
    "        likelihoods = [(expectations[c], p) for c, p in likelihoods]\n",
    "        return likelihoods\n",
    "    \n",
    "    def __call__(self, sentence: str, trial_count=5) -> List[float]:\n",
    "        results = {category[\"name\"]: 0.0 for category in self.categories}\n",
    "        for _ in range(trial_count):\n",
    "            likelihoods = self.classify_once(sentence)\n",
    "            for category, likelihood in likelihoods:\n",
    "                results[category] += likelihood / trial_count\n",
    "        results = list(results.items())\n",
    "        results.sort(key=lambda x: x[1], reverse=True)\n",
    "        return results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: power\n",
      "Sentence: It is good to be in positions of control over others.\n",
      "[('power', 1.5735400575067617e-05), ('security', 5.408409805340852e-07), ('hedonism', 2.697648396676045e-12), ('stimulation', 9.902645078556016e-13), ('universalism', 7.239746125625535e-13), ('self-direction', 1.0493404793554133e-16), ('conformity', 2.4926434854530225e-17), ('achievement', 1.3719116353619749e-17), ('tradition', 1.1326183739056887e-18), ('benevolence', 3.094664027244362e-25)]\n",
      "Correct!\n"
     ]
    }
   ],
   "source": [
    "classifier = LikelihoodBasedCategoryClassifier(categories)\n",
    "# take a random category \n",
    "category = categories[np.random.randint(len(categories))]\n",
    "sentence = np.random.choice(category[\"examples\"])\n",
    "print(f\"Category: {category['name']}\")\n",
    "print(f\"Sentence: {sentence}\")\n",
    "\n",
    "likelihoods = classifier(sentence)\n",
    "print(likelihoods)\n",
    "if likelihoods[0][0] == category[\"name\"]:\n",
    "    print(\"Correct!\")\n",
    "else:\n",
    "    print(\"Incorrect!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.14\n"
     ]
    }
   ],
   "source": [
    "# basic evaluation go throguuh all categories and all examples\n",
    "def evaluate_classifier(classifier, categories, trial_count=5):\n",
    "    results = {category[\"name\"]: [] for category in categories}\n",
    "    \n",
    "    for category in categories:\n",
    "        for sentence in category[\"examples\"]:\n",
    "            likelihoods = classifier(sentence, trial_count=trial_count)\n",
    "            results[category[\"name\"]].append(likelihoods)\n",
    "    # compute accuracy\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for category in categories:\n",
    "        for likelihoods in results[category[\"name\"]]:\n",
    "            if likelihoods[0][0] == category[\"name\"]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "    accuracy = correct / total\n",
    "    return accuracy, results\n",
    "\n",
    "accuracy, results = evaluate_classifier(classifier, categories)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
