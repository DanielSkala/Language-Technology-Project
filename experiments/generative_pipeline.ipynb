{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mo\\Documents\\Organisations\\RUG\\Language-Technology-Project\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "try:\n",
    "    os.chdir(os.path.join(os.getcwd(), '../../Language-Technology-Project'))\n",
    "    print(os.getcwd())\n",
    "except:\n",
    "    print(\"ALready in current dir\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size_gb(model) = 5.80 GB\n",
      "vocab size: 50257\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2-xl')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2-xl').to(device)\n",
    "\n",
    "print(f\"size_gb(model) = {model.num_parameters() * 4 / 1024**3:.2f} GB\")\n",
    "print(\"vocab size:\", tokenizer.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 9, 50257])\n",
      "Top 5 tokens:\n",
      "1:  woman (0.11)\n",
      "2:  doctor (0.08)\n",
      "3:  nurse (0.05)\n",
      "4:  mother (0.04)\n",
      "5:  man (0.03)\n"
     ]
    }
   ],
   "source": [
    "text = \"Man is a doctor as a women is a\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt').to(device)\n",
    "output = model(**encoded_input)\n",
    "print(output.logits.shape)\n",
    "next_token_logits = output.logits[:, -1, :]\n",
    "likelihoods = torch.softmax(next_token_logits, dim=-1)\n",
    "sorted_likelihoods, sorted_indices = torch.sort(likelihoods, descending=True)\n",
    "print(\"Top 5 tokens:\")\n",
    "for i in range(5):\n",
    "    print(f\"{i+1}: {tokenizer.decode(sorted_indices[0, i])} ({sorted_likelihoods[0, i]:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('nurse', 1.080520402501984e-10),\n",
       " ('doctor', 6.820724138378864e-06),\n",
       " ('teacher', 1.1379043641373526e-11)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def get_likelihoods_of_words_given_context(prompt: str, words: list, model, tokenizer):\n",
    "    \"\"\"\n",
    "    Returns a list of likelihoods of words given a prompt.\n",
    "    \"\"\"\n",
    "    word_probs = []\n",
    "\n",
    "    for word in words:\n",
    "        word_token = tokenizer.encode(word, add_special_tokens=False)\n",
    "        tokens = tokenizer(prompt, return_tensors='pt')['input_ids'].to(device)\n",
    "        tokens = torch.cat([tokens, torch.tensor(word_token).unsqueeze(0).to(device)], dim=-1)\n",
    "        outputs = model(tokens)\n",
    "        logits = outputs[0]\n",
    "        probabilities = torch.softmax(logits, dim=-1)\n",
    "\n",
    "        if len(word_token) == 1:\n",
    "            word_prob = probabilities[0, -1, word_token[0]].item()\n",
    "            word_probs.append(word_prob)\n",
    "        else:\n",
    "            word_prob = 1.0\n",
    "            for idx in range(len(word_token)):\n",
    "                word_prob *= probabilities[0, -(len(word_token) - idx), word_token[idx]].item()\n",
    "            word_probs.append(word_prob)\n",
    "\n",
    "    return list(zip(words, word_probs))\n",
    "# example\n",
    "prompt = \"Man is a doctor as a women is a\"\n",
    "get_likelihoods_of_words_given_context(prompt, [\"nurse\", \"doctor\", \"teacher\"], model, tokenizer)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Category classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\n",
    "    {\n",
    "        \"name:\": \"universalism\",\n",
    "        \"description\": \"Understanding, appreciation, tolerance, and protection for the welfare of all people and for nature.\",\n",
    "        \"examples\": [\n",
    "            \"Equality is important to me.\",\n",
    "            \"It is good to accept and try to understand those who are different from oneself.\"\n",
    "        ],\n",
    "        \"children\": []\n",
    "    },\n",
    "    {\n",
    "        \"name:\": \"self-direction\",\n",
    "        \"description\": \"Independent thought and action; choosing, creating, exploring.\",\n",
    "        \"examples\": [\n",
    "            \"It is good to search for the truth and think in a rational and unbiased way.\",\n",
    "            \"Independence is important for me to make my own decisions.\",\n",
    "        ],\n",
    "        \"children\": []\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"stimulation\",\n",
    "        \"description\": \"It is good to experience excitement, novelty, and change.\",\n",
    "        \"examples\": [\n",
    "            \"Have an exciting life: arguments towards allowing people to experience foreign places and special activities or having perspective-changing experiences\",\n",
    "            \"Have a varied life: arguments towards allowing people to engage in many activities and change parts of their life or towards promoting local clubs (sports, ...)\",\n",
    "            \"Be daring: arguments towards more risk-taking\"\n",
    "        ],\n",
    "        \"children\": []\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"hedonism\",\n",
    "        \"description\": \"Pleasure or sensuous gratification for oneself.\",\n",
    "        \"examples\": [\n",
    "            \"It is important to do things that make you feel good.\",\n",
    "            \"It is important to have a good time.\",\n",
    "        ],\n",
    "        \"children\": []\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"achievement\",\n",
    "        \"description\": \"It is good to be successful in accordance with social norms.\",\n",
    "        \"examples\": [\n",
    "            \"It is important to show your abilities.\",\n",
    "            \"Be ambitious: arguments towards allowing for ambitions and climbing up the social ladder\",\n",
    "            \"Have success: arguments towards allowing for success and recognizing achievements\",\n",
    "            \"Be capable: arguments towards acquiring competence in certain tasks, being more effective, and showing competence in solving tasks\",\n",
    "            \"Be intellectual: arguments towards acquiring high cognitive skills, being more reflective, and showing intelligence\",\n",
    "            \"Be courageous: arguments towards being more courageous and having people stand up for their beliefs\"\n",
    "        ],\n",
    "        \"children\": []\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"power\",\n",
    "        \"description\": \"Social status and prestige, control or dominance over people and resources.\",\n",
    "        \"examples\": [\n",
    "            \"It is important to be rich.\",\n",
    "            \"It is good to be in positions of control over others.\",\n",
    "        ],\n",
    "        \"children\": []\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"security\",\n",
    "        \"description\": \"Safety, harmony, and stability of society, of relationships, and of self.\",\n",
    "        \"examples\": [\n",
    "            \"It is important to live in secure surroundings.\",\n",
    "            \"It is important to plan ahead so as to avoid surprises.\",\n",
    "        ],\n",
    "        \"children\": []\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"tradition\",\n",
    "        \"description\": \"Respect, commitment, and acceptance of the customs and ideas that traditional culture or religion provide the self.\",\n",
    "        \"examples\": [\n",
    "            \"It is important to uphold traditions.\",\n",
    "            \"It is important to follow the customs of my religion.\",\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"conformity\",\n",
    "        \"description\": \"Restraint of actions, inclinations, and impulses likely to upset or harm others and violate social expectations or norms.\",\n",
    "        \"examples\": [\n",
    "            \"It is important to behave properly.\",\n",
    "            \"It is important to respect traditions.\",\n",
    "        ],\n",
    "        \"children\": []\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"benevolence\",\n",
    "        \"description\": \"Preservation and enhancement of the welfare of people with whom one is in frequent personal contact.\",\n",
    "        \"examples\": [\n",
    "            \"It is important to help the people around you.\",\n",
    "            \"It is important to be loyal to your friends.\",\n",
    "        ],\n",
    "        \"children\": []\n",
    "    }\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
