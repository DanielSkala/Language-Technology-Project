{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mo\\Documents\\Organisations\\RUG\\Language-Technology-Project\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from typing import List, Tuple, Dict, Union, Any, Optional\n",
    "from tqdm import tqdm\n",
    "try:\n",
    "    os.chdir(os.path.join(os.getcwd(), '../../Language-Technology-Project'))\n",
    "    print(os.getcwd())\n",
    "except:\n",
    "    print(\"ALready in current dir\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is available\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"{device} is available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size_gb(model) = 5.80 GB\n",
      "vocab size: 50257\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2-xl')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2-xl').to(device)\n",
    "\n",
    "# from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "# model = AutoModelForCausalLM.from_pretrained('mosaicml/mpt-1b-redpajama-200b', trust_remote_code=True).to(device)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neox-20b\")\n",
    "\n",
    "print(f\"size_gb(model) = {model.num_parameters() * 4 / 1024**3:.2f} GB\")\n",
    "print(\"vocab size:\", tokenizer.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " a\n"
     ]
    }
   ],
   "source": [
    "def predict_next_token_logits(text):\n",
    "    encoded_input = tokenizer(text, return_tensors='pt').to(device)\n",
    "    encoded_input['attention_mask'] = encoded_input['attention_mask'].bool()\n",
    "    output = model(**encoded_input)\n",
    "    next_token_logits = output.logits[:, -1, :]\n",
    "    return next_token_logits\n",
    "\n",
    "def decode_token_logits(logits):\n",
    "    return tokenizer.decode(torch.argmax(logits, dim=-1))\n",
    "\n",
    "text = \"Daniel Skala is\"\n",
    "logits = predict_next_token_logits(text)\n",
    "print(decode_token_logits(logits))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daniel skala is a member of the Swedish national team and has played for the Swedish national team since\n"
     ]
    }
   ],
   "source": [
    "text = \"Daniel skala is\"\n",
    "for i in range(16):\n",
    "    logits = predict_next_token_logits(text)\n",
    "    text += decode_token_logits(logits)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('4', 0.20943237841129303),\n",
       " ('5', 0.17149624228477478),\n",
       " ('3', 0.14209160208702087),\n",
       " ('6', 0.06978660076856613),\n",
       " ('7', 0.05673491582274437),\n",
       " ('8', 0.031708039343357086),\n",
       " ('2', 0.027894824743270874),\n",
       " ('9', 0.022482799366116524),\n",
       " ('10', 0.007341871503740549)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def get_likelihoods_of_words_given_context(prompt: str, words: list, model, tokenizer):\n",
    "    \"\"\"\n",
    "    Returns a list of likelihoods of words given a prompt.\n",
    "    \"\"\"\n",
    "    logits = predict_next_token_logits(prompt)\n",
    "    likelihoods = torch.softmax(logits, dim=-1)\n",
    "    \n",
    "    word_probs = []\n",
    "    for word in words:\n",
    "        tokens = tokenizer.encode(word)\n",
    "        probability = 1\n",
    "        for token in tokens:\n",
    "            probability *= likelihoods[0, token].item()\n",
    "        word_probs.append((word, probability))\n",
    "    output = sorted(word_probs, key=lambda x: x[1], reverse=True)\n",
    "    output.sort(key=lambda x: x[1], reverse=True)\n",
    "    return output\n",
    "# example\n",
    "prompt = \"2+2=\"\n",
    "options = [\"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\"]\n",
    "get_likelihoods_of_words_given_context(prompt, options, model, tokenizer)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Category classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "from settings import categories\n",
    "\n",
    "class LikelihoodBasedCategoryClassifier:\n",
    "\n",
    "    def __init__(self, categories):\n",
    "        self.categories = categories\n",
    "\n",
    "    def __shuffle_categories(self):\n",
    "        np.random.shuffle(self.categories)\n",
    "    \n",
    "    def __construct_classification_prompt(self, sentence, max_length=128, categories=None):\n",
    "        prompt = \"Categories of Human Value Detection categories: \\n\\n\"\n",
    "        expectation2category = {}\n",
    "        for i, category in enumerate(categories):\n",
    "            name = category[\"name\"]\n",
    "            description = category[\"description\"]\n",
    "            examples = category[\"examples\"]\n",
    "            example = examples[np.random.randint(len(examples))]\n",
    "            example = example[:max_length] + \"...\" if len(example) > max_length else example\n",
    "            # otpions a-z\n",
    "            option = chr(ord('A') + i)\n",
    "            prompt += f\"{option}. {name}: {description} (e.g., {example})\\n\"\n",
    "            prompt += f\"{name}\\n\"\n",
    "            expectation2category[option] = name\n",
    "        prompt += f\"\\n\\\"{sentence}\\\" is an example of \" \n",
    "\n",
    "        return prompt, expectation2category\n",
    "    \n",
    "    def __construct_comparison_prompts(self, sentence, max_length=128, categories=None):\n",
    "        prompts = []\n",
    "        for category in self.categories:\n",
    "            name = category[\"name\"]\n",
    "            description = category[\"description\"]\n",
    "            examples = category[\"examples\"]\n",
    "            example = examples[np.random.randint(len(examples))]\n",
    "            example = example[:max_length] + \"...\" if len(example) > max_length else example\n",
    "            prompt = f\"Category: {name}\"\n",
    "            prompt += f\"\\ndefinition: {description}\"\n",
    "            prompt += f\"\\nexample: {example}\"\n",
    "            prompt += f\"\\n\\n\\\"{sentence}\\\" is an related to {name}? (T/F)\"\n",
    "            prompt += f\"\\nanswer: \"\n",
    "            print(prompt)\n",
    "            prompts.append((category, prompt))\n",
    "        return prompts\n",
    "\n",
    "    def classify_once(self, sentence: str) -> List[float]:\n",
    "        self.__shuffle_categories()\n",
    "        prompt, expectations = self.__construct_classification_prompt(sentence, categories=self.categories)\n",
    "        likelihoods = get_likelihoods_of_words_given_context(prompt, list(expectations.keys()), model, tokenizer)\n",
    "        likelihoods = [(expectations[c], p) for c, p in likelihoods]\n",
    "        # trueOrFalse_prompts = self.__construct_comparison_prompts(sentence, categories=self.categories)\n",
    "        # likelihoods = []\n",
    "        # print(trueOrFalse_prompts)\n",
    "        # for (category, prompt) in trueOrFalse_prompts:\n",
    "        #     probabilities = get_likelihoods_of_words_given_context(prompt, [\"T\", \"F\"], model, tokenizer)\n",
    "        #     for (word, probability) in probabilities:\n",
    "        #         if word == \"T\":\n",
    "        #             likelihoods.append((category[\"name\"], probability))\n",
    "        # likelihoods.sort(key=lambda x: x[1], reverse=True)\n",
    "        return likelihoods\n",
    "    \n",
    "    def __call__(self, sentence: str, trial_count=1) -> List[float]:\n",
    "        results = {category[\"name\"]: 0.0 for category in self.categories}\n",
    "        for _ in range(trial_count):\n",
    "            likelihoods = self.classify_once(sentence)\n",
    "            for category, likelihood in likelihoods:\n",
    "                results[category] += likelihood / trial_count\n",
    "        results = list(results.items())\n",
    "        results.sort(key=lambda x: x[1], reverse=True)\n",
    "        return results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: conformity\n",
      "Sentence: It is important to behave properly.\n",
      "[('security', 6.525160188175505e-06), ('achievement', 3.554343038558727e-06), ('self-direction', 1.3102259117658832e-06), ('universalism', 1.2354994396446273e-06), ('benevolence', 1.167884647657047e-06), ('hedonism', 6.931448410796293e-07), ('power', 4.4942350996279856e-07), ('conformity', 2.9375530630204594e-07), ('stimulation', 2.7255561008132645e-07), ('tradition', 2.405157033535943e-07)]\n",
      "Incorrect!\n"
     ]
    }
   ],
   "source": [
    "classifier = LikelihoodBasedCategoryClassifier(categories)\n",
    "# take a random category \n",
    "category = categories[np.random.randint(len(categories))]\n",
    "sentence = np.random.choice(category[\"examples\"])\n",
    "print(f\"Category: {category['name']}\")\n",
    "print(f\"Sentence: {sentence}\")\n",
    "\n",
    "likelihoods = classifier(sentence)\n",
    "print(likelihoods)\n",
    "if likelihoods[0][0] == category[\"name\"]:\n",
    "    print(\"Correct!\")\n",
    "else:\n",
    "    print(\"Incorrect!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic evaluation go throguuh all categories and all examples\n",
    "def evaluate_classifier(classifier, categories, trial_count=5):\n",
    "    results = {category[\"name\"]: [] for category in categories}\n",
    "    \n",
    "    for category in categories:\n",
    "        for sentence in category[\"examples\"]:\n",
    "            likelihoods = classifier(sentence, trial_count=trial_count)\n",
    "            results[category[\"name\"]].append(likelihoods)\n",
    "    # compute accuracy\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for category in categories:\n",
    "        for likelihoods in results[category[\"name\"]]:\n",
    "            if likelihoods[0][0] == category[\"name\"]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "    accuracy = correct / total\n",
    "    return accuracy, results\n",
    "\n",
    "accuracy, results = evaluate_classifier(classifier, categories)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
