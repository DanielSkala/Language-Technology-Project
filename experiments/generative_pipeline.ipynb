{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mo\\Documents\\Organisations\\RUG\\Language-Technology-Project\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from typing import List, Tuple, Dict, Union, Any, Optional\n",
    "from tqdm import tqdm\n",
    "try:\n",
    "    os.chdir(os.path.join(os.getcwd(), '../../Language-Technology-Project'))\n",
    "    print(os.getcwd())\n",
    "except:\n",
    "    print(\"ALready in current dir\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is available\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"{device} is available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size_gb(model) = 5.80 GB\n",
      "vocab size: 50257\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2-xl')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2-xl').to(device)\n",
    "\n",
    "# from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "# model = AutoModelForCausalLM.from_pretrained('mosaicml/mpt-1b-redpajama-200b', trust_remote_code=True).to(device)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neox-20b\")\n",
    "\n",
    "print(f\"size_gb(model) = {model.num_parameters() * 4 / 1024**3:.2f} GB\")\n",
    "print(\"vocab size:\", tokenizer.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " a\n"
     ]
    }
   ],
   "source": [
    "def predict_next_token_logits(text):\n",
    "    encoded_input = tokenizer(text, return_tensors='pt').to(device)\n",
    "    encoded_input['attention_mask'] = encoded_input['attention_mask'].bool()\n",
    "    output = model(**encoded_input)\n",
    "    next_token_logits = output.logits[:, -1, :]\n",
    "    return next_token_logits\n",
    "\n",
    "def decode_token_logits(logits):\n",
    "    return tokenizer.decode(torch.argmax(logits, dim=-1))\n",
    "\n",
    "text = \"Daniel Skala is\"\n",
    "logits = predict_next_token_logits(text)\n",
    "print(decode_token_logits(logits))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daniel skala is a member of the Swedish national team and has played for the Swedish national team since\n"
     ]
    }
   ],
   "source": [
    "text = \"Daniel skala is\"\n",
    "for i in range(16):\n",
    "    logits = predict_next_token_logits(text)\n",
    "    text += decode_token_logits(logits)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('4', 0.20943237841129303),\n",
       " ('5', 0.17149624228477478),\n",
       " ('3', 0.14209160208702087),\n",
       " ('6', 0.06978660076856613),\n",
       " ('7', 0.05673491582274437),\n",
       " ('8', 0.031708039343357086),\n",
       " ('2', 0.027894824743270874),\n",
       " ('9', 0.022482799366116524),\n",
       " ('10', 0.007341871503740549)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def get_likelihoods_of_words_given_context(prompt: str, words: list, model, tokenizer):\n",
    "    \"\"\"\n",
    "    Returns a list of likelihoods of words given a prompt.\n",
    "    \"\"\"\n",
    "    logits = predict_next_token_logits(prompt)\n",
    "    likelihoods = torch.softmax(logits, dim=-1)\n",
    "    \n",
    "    word_probs = []\n",
    "    for word in words:\n",
    "        tokens = tokenizer.encode(word)\n",
    "        probability = 1\n",
    "        for token in tokens:\n",
    "            probability *= likelihoods[0, token].item()\n",
    "        word_probs.append((word, probability))\n",
    "    output = sorted(word_probs, key=lambda x: x[1], reverse=True)\n",
    "    output.sort(key=lambda x: x[1], reverse=True)\n",
    "    return output\n",
    "# example\n",
    "prompt = \"2+2=\"\n",
    "options = [\"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\"]\n",
    "get_likelihoods_of_words_given_context(prompt, options, model, tokenizer)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Category classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from settings import categories\n",
    "\n",
    "class LikelihoodBasedCategoryClassifier:\n",
    "\n",
    "    def __init__(self, categories):\n",
    "        self.categories = categories\n",
    "\n",
    "    def __shuffle_categories(self):\n",
    "        np.random.shuffle(self.categories)\n",
    "    \n",
    "    def __construct_classification_prompt(self, sentence, max_length=128, categories=None):\n",
    "        prompt = \"Categories of Human Value Detection 2023 by name and description: \\n\\n\"\n",
    "        expectation2category = {}\n",
    "        for i, category in enumerate(categories):\n",
    "            name = category[\"name\"]\n",
    "            description = category[\"description\"]\n",
    "            examples = category[\"examples\"]\n",
    "            example = examples[np.random.randint(len(examples))]\n",
    "            example = example[:max_length] + \"...\" if len(example) > max_length else example\n",
    "            # otpions a-z\n",
    "            prompt += f\"- {name}: {description} (e.g., {example})\\n\"\n",
    "            expectation2category[name] = name\n",
    "        prompt += \"\\n\"\n",
    "        prompt += \"Classify the following sentence into one of the categories above:\\n\"\n",
    "        prompt += f\"\\n'Argument: {sentence}\"\n",
    "        prompt += \"\\Category: \"\n",
    "\n",
    "        return prompt, expectation2category\n",
    "\n",
    "    def classify_once(self, sentence: str) -> List[float]:\n",
    "        self.__shuffle_categories()\n",
    "        prompt, expectations = self.__construct_classification_prompt(sentence, categories=self.categories)\n",
    "        likelihoods = get_likelihoods_of_words_given_context(prompt, expectations.keys(), model, tokenizer)\n",
    "        likelihoods = [(expectations[c], p) for c, p in likelihoods]\n",
    "        return likelihoods\n",
    "    \n",
    "    def __call__(self, sentence: str, trial_count=5) -> List[float]:\n",
    "        results = {category[\"name\"]: 0.0 for category in self.categories}\n",
    "        for _ in range(trial_count):\n",
    "            likelihoods = self.classify_once(sentence)\n",
    "            for category, likelihood in likelihoods:\n",
    "                results[category] += likelihood / trial_count\n",
    "        results = list(results.items())\n",
    "        results.sort(key=lambda x: x[1], reverse=True)\n",
    "        return results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: tradition\n",
      "Sentence: It is important to uphold traditions.\n",
      "[('power', 1.4389633179234806e-06), ('security', 1.725019046716625e-07), ('hedonism', 1.9224981485055905e-12), ('universalism', 7.754738759744585e-13), ('stimulation', 1.3023530049415537e-13), ('self-direction', 1.3722310033501966e-16), ('conformity', 3.287640357351561e-17), ('achievement', 8.669216331821405e-18), ('tradition', 4.708284174645064e-19), ('benevolence', 7.21391911915258e-25)]\n",
      "Incorrect!\n"
     ]
    }
   ],
   "source": [
    "classifier = LikelihoodBasedCategoryClassifier(categories)\n",
    "# take a random category \n",
    "category = categories[np.random.randint(len(categories))]\n",
    "sentence = np.random.choice(category[\"examples\"])\n",
    "print(f\"Category: {category['name']}\")\n",
    "print(f\"Sentence: {sentence}\")\n",
    "\n",
    "likelihoods = classifier(sentence)\n",
    "print(likelihoods)\n",
    "if likelihoods[0][0] == category[\"name\"]:\n",
    "    print(\"Correct!\")\n",
    "else:\n",
    "    print(\"Incorrect!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.14\n"
     ]
    }
   ],
   "source": [
    "# basic evaluation go throguuh all categories and all examples\n",
    "def evaluate_classifier(classifier, categories, trial_count=5):\n",
    "    results = {category[\"name\"]: [] for category in categories}\n",
    "    \n",
    "    for category in categories:\n",
    "        for sentence in category[\"examples\"]:\n",
    "            likelihoods = classifier(sentence, trial_count=trial_count)\n",
    "            results[category[\"name\"]].append(likelihoods)\n",
    "    # compute accuracy\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for category in categories:\n",
    "        for likelihoods in results[category[\"name\"]]:\n",
    "            if likelihoods[0][0] == category[\"name\"]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "    accuracy = correct / total\n",
    "    return accuracy, results\n",
    "\n",
    "accuracy, results = evaluate_classifier(classifier, categories)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
